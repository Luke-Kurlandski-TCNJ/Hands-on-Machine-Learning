{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: The Machine Learning Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "### Supervised vs Unsupervised\n",
    "The amount of supervision an algoithms recieves.\n",
    "#### Supervised Learning\n",
    "Supervised Learning - dataset fed to algorithm includes the solutions aka \"labels\"\n",
    "<br>Regression - predicting a value, given an input feature\n",
    "#### Unsupervised Learning\n",
    "Unsupervised Learning - dataset is unlabeled\n",
    "<br>Dimentionality Reduction - simply data and minimize loss of information\n",
    "<br>Feature Extraction - clumping related features together to reduce data size, eg car mileage and car mass\n",
    "<br>Anamoly Detection - detect outlyers in data\n",
    "<br>Novelty Detection - detect new instances in data\n",
    "<br>Association Rule Learning - find relationship between data\n",
    "#### Semisupervised Learning\n",
    "Semisupervised Learning - dataset is partially labeled\n",
    "<br>Often, data is trained unsupervised, then data is clustered, and finally a few supervision rules are applied to fine tune the entire system.\n",
    "#### Reinforcment Learning\n",
    "Reinforcemnet Learning - a learning system, or agent, learns from the rewards and penalties of its actions\n",
    "### Batch and Online Learning\n",
    "Whether the algorithm learns incrementally or not.\n",
    "#### Batch Learning\n",
    "Batch Learning - training an algorithm with all the data at a single time\n",
    "<br>Offline Learning - training the algorithm while the product is not functional\n",
    "#### Online Learning\n",
    "Online Learning - training an algorithm dynamically, while it is performing its task\n",
    "<br>Learning Rate - the rate a system adapts to new data\n",
    "### Instance-Based Versus Model-Based Learning\n",
    "How an algorithm generalizes, the tranfer from labeled data to unlabeled.\n",
    "#### Instance-Based Learning\n",
    "Instance Based Learning - generalizing labeled data to new data through a similarity comparasin\n",
    "<br>Measure of Similarity - a method of determining how similar two pieces of data are\n",
    "#### Model-Based Learning\n",
    "Model Based Learning - generalizing labeled data to new data through mathematical predictions\n",
    "<br>Cost Function - a measurment of how \"bad\" the mathematical function is\n",
    "## Main Challenges of Machine Learning\n",
    "### Insufficient Quantity of Data\n",
    "Research shows that the quantity of data is generally more important than the quality of an ML algorithm.\n",
    "### Nonrepresentative Data\n",
    "To generalize well, training data must represent new cases well.\n",
    "### Poor Quality Data\n",
    "Training data should be cleaned up (outliers discarded ect) to improve accuracy.\n",
    "### Irrelevant Features \n",
    "Feature Engineering - generating features to train algorithm on; involves the following:\n",
    "<br>Feature Selection - selecting the most useful features to train\n",
    "<br>Feature Extraction - combining features or using dimentionality reduction to get more useful features\n",
    "### Overfitting the Training Data\n",
    "Overfitting - a model that fits the training data suberbly, but generalizes to new data poorly\n",
    "<br>Regularization - simplifying a model to prevent overfitting\n",
    "<br>Degrees of Freedom - number of constants in a model that may be adjusted to fit data\n",
    "<br>Hyperparameter - parameter of a learning algorithm (not model) that controls the amount of regularization in a model\n",
    "### Underfitting the Training Data\n",
    "Underfitting - a model that is too simple to fit new data well\n",
    "<br>Improved by selecting a better model, improved feature engineering, or reducing regulatization of hyperparameter. \n",
    "## Testing and Validating\n",
    "Split data into multiple portions: training sets (~80%) and test sets (~20%)\n",
    "<br>Generalization Error - the error rate testing new cases\n",
    "### Hyperparameter Tuning and Model Selection\n",
    "To improve accuracy, one can train multiple models with the reduced training set, test the model with the validation set, and select the best model. Then retrain this model with the entire training set to produce the final model.\n",
    "<br>Validation Set - a smaller portion of the training set\n",
    "<br>Reduced Training Set - training set minus validation set\n",
    "<br>Cross-Validation - performing the above process repeatedly with different, small validation sets\n",
    "### Data Mismatch\n",
    "After hyperparameter tuning and model selection, test model with the train-dev set. If results are poor, then the only reasonable explaination is that the training data did not accurately represent new data.\n",
    "<br>Train-Dev Set - one more subcategory of training data, used after hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
